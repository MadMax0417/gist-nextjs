export interface DataItem {
    title: string;
    code: string;
}

export const data : DataItem[] = [
  {
  "title": "data-manipulation",
  "code": "import pandas as pd \ndata =[['Ram',18],['Shyam',16],['Shiv',20]] \ndf=pd.DataFrame(data,columns=['Name','Age']) \nprint (df) \n\n\n\ndata = {'Name': ['Ram','Shyam','Shiv'], \n        'Age': [18, 16, 20]} \ndf = pd.DataFrame(data) \n# declare a new list \naddress = ['New Delhi', 'Mumbai', 'Kolkata'] \n# assign the list as a column \ndf['Address'] = address \nprint(df)\n\n\n\ndata = {'Name': ['Ram','Shyam','Shiv'], \n        'Age': [18, 16, 20], \n        'Address':['New Delhi', 'Mumbai', 'Kolkata']} \ndf = pd.DataFrame(data)  \nprint(\"Original DataFrame:\")  \nprint(df)  \nprint()  \n# add a new row  \ndf.loc[len(df.index)] = ['Ganesh', 12, 'Hyderabad']  \nprint(\"Modified DataFrame:\")  \nprint(df)\n\n\n\nimport pandas as pd\ndata = {'Name':['Ram', 'Shyam', 'Shiv', 'Radha', 'Gauri', 'Girija'], \n        'Age': [25, 20, 30, 18, 26, 25],  \n        'City': ['Delhi', 'Mumbai', 'Kailash', 'Ujjain', 'Chennai', 'Shimla']} \ndf=pd.DataFrame(data) \nprint(\"Original DataFrame:\")  \nprint(df)  \nprint()  \n# delete row with index 4 \ndf.drop(4, axis=0, inplace=True) \n# delete row with index 5 \ndf.drop(index=5, inplace=True) \n# delete rows with index 1 and 3 \ndf.drop([1, 3], axis=0, inplace=True) \n# display the modified DataFrame after deleting rows \nprint(\"Modified DataFrame:\") \nprint(df)\n\n\n\nimport pandas as pd \n# create a sample DataFrame \ndata = {'Name': ['Ravi', 'Anil', 'Mukseh', 'Rahul'], \n        'Age': [25, 30, 35, 40], \n        'City': ['New Delhi', 'Bhopal', 'Varanasi', 'Pune'], \n        'Height': ['165', '178', '185', '171'], \n        'Profession': ['Engineer', 'Entrepreneur', 'Unemployed', 'Actor'], \n        'Marital Status': ['Single', 'Married', 'Divorced', 'Engaged']} \ndf = pd.DataFrame(data) \n# display the original DataFrame \nprint(\"Original DataFrame:\") \nprint(df) \nprint() \n# delete age column \ndf.drop('Age', axis=1, inplace=True) \n# delete marital status column \ndf.drop(columns='Marital Status', inplace=True) \n# delete height and profession columns \ndf.drop(['Height', 'Profession'], axis=1, inplace=True) \n# display the modified DataFrame after deleting rows \nprint(\"Modified DataFrame:\") \nprint(df)\n\n\n\ndata = {'Name': ['Alice', 'Bob', 'Charlie', 'David'], \n        'Age': [25, 30, 35, 40], \n        'City': ['New York', 'London', 'Paris', 'Tokyo']} \ndf = pd.DataFrame(data) \n# display the original DataFrame \nprint(\"Original DataFrame:\") \nprint(df) \nprint() \n# rename column 'Name' to 'First_Name' \ndf.rename(columns= {'Name': 'First_Name'}, inplace=True) \n# rename columns 'Age' and 'City' \ndf.rename(mapper= {'Age': 'Number', 'City':'Address'}, axis=1, \ninplace=True) \n# display the DataFrame after renaming column \nprint(\"Modified DataFrame:\") \nprint(df)\n\n\n\nimport pandas as pd \n# create a sample DataFrame \ndata = {'Name': ['Alice', 'Bob', 'Charlie', 'David'], \n        'Age': [25, 30, 35, 40], \n        'City': ['New York', 'London', 'Paris', 'Tokyo']} \ndf = pd.DataFrame(data) \n# display the original DataFrame \nprint(\"Original DataFrame:\") \nprint(df) \nprint() \n# rename column one index label \ndf.rename(index={0: 7}, inplace=True) \n# rename columns multiple index labels \ndf.rename(mapper={1: 10, 2: 100}, axis=0, inplace=True) \n# display the DataFrame after renaming column \nprint(\"Modified DataFrame:\") \nprint(df)"
},
 {
  "title": "calculating",
  "code": "import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n##1-MEAN()\ndata=[168,170,150,160,182,140,175,191,152,150] \nprint(data) \nmean=np.mean(data) \nprint(mean) \n\n\n##2.1-MEDIAN(even)\ndata=[168,170,150,160,182,140,175,191,152,150] \ndata.sort() \nprint(data) \nmedian=np.median(data) \nprint(median) \n\n\n##2.2-MEDIAN(odd)\nimport numpy as np \ndata =[168,170,150,160,182,140,175,191,152] \ndata.sort() \nprint(data) \nmedian=np.median(data) \nprint(median) \n\n\n##3-MODE \nimport statistics as stats \ndata = [168,170,150,160,182,140,175,191,152,150] \nstats.mode(data)\n\n\n##4-VARIANCE\ndata = [168,170,150,160,182,140,175,191,152,150] \nmean=np.mean(data) \nprint(mean) \nvariance= np.var(data) \nprint(variance) \n\n\n##5-STANDARD DEVIATION\ndata=[168,170,150,160,182,140,175,191,152,150] \nprint(data) \nstandard_deviation=np.std(data) \nprint(standard_deviation) \n\n\n##6-CORRELATION\norbital_period = np.array([88, 225, 365, 460, 687, 1200, 2223, 3831, 5854, 8756, 10015, 20687, 30765, 40190]) #days \ndist_from_sun = np.array([58, 108, 250, 328, 486, 978, 1287, 1890, 2060, 2396, 3400, 3845, 4500, 4800]) #million km \nprint(orbital_period, dist_from_sun)  \ncorrelation_coeff = np.corrcoef(orbital_period, dist_from_sun) \nprint(correlation_coeff )\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt\norbital_period = np.array([88, 225, 365, 460, 687, 1200, 2223, 3831, 5854, 8756, 10015, 20687, 30765, 40190])    #days \ndist_from_sun = np.array([58, 108, 250, 328, 486, 978, 1287, 1890, 2060, 2396, 3400, 3845, 4500, 4800]) #million km \nplt.scatter(orbital_period, dist_from_sun) \nplt.title(\"Correlation Plot\") \nplt.xlabel = (\"Orbital Period (days)\") \nplt.ylabel = (\"Distance from Sun (million km)\") \nplt.show() \n\n\n##7-NORMAL DISTRIBUTION\ndef normal_dist(x, mean, sd): \n   prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2) \n   return prob_density \nmean = 0 \nsd = 1 \nx = 1 \nresult = normal_dist(x, mean, sd) \nprint(result) \n\n \nimport numpy as np  \nimport matplotlib.pyplot as plt  \nfrom scipy.stats import norm  \nimport statistics    \nx_axis = np.arange(-10, 10, 0.01)    \nmean = statistics.mean(x_axis)  \nsd = statistics.stdev(x_axis)  \nplt.plot(x_axis, norm.pdf(x_axis, mean, sd))  \nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt   \nMean = 100 \nStandard_deviation  = 5 \n#size \nsize = 100000  \nvalues = np.random.normal(Mean, Standard_deviation, size)  \nplt.hist(values, 100)  \nplt.axvline(values.mean(), color='k', linestyle='dashed',linewidth=2) \nplt.show()  (Calculating title)"
},{
  "title": "csv-file",
  "code": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndf = pd.read_csv(r\"   .csv”) \ndf \n\ndf.head() \n\ndf.tail()\n\nDimension = df.shape  \nprint (\"DIMENSION:\", Dimension) \n\ndf.size \n\ndf.index \n\ncol = df.columns  \nprint(\"Columns:\\n\", col) \n\ndatatype= df.dtypes \nprint(datatype) \n\nSummary = df.info() \nprint(Summary)\n\ndesc = df.describe() \nprint(desc) \n\ndf.memory_usage()  (optional)\n\ndf.empty\n\ndf.isnull() \n\ndf.isnull().sum()\n\ndf.notnull() \n\ndf.dropna() \n\ndf.fillna(0)\n\ndf.corr()  \n\nimport seaborn as sns\ncorrelation = df.corr() \nsns.heatmap(correlation, annot=True, cmap='RdYlBu') \nplt.show()"
}, 
 {
    "title": "matplotlib-plots",
    "code": "import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \ndf = pd.read_csv(r\"   .csv\") \ndf\n\ndf.head()\n\ndf= df.drop(columns=['Pregnancies', 'SkinThickness', 'DiabetesPedigreeFunction', 'Insulin', 'Outcome']) \ndf \n\ndf = df.drop(df.index[10:]) \ndf\n\n##Plotting LINE Chart\n#create a line plot of different color for each feature \ndf.plot(kind='line', color=['red','blue','brown','green']) \n#Set title to \"Features responsible for diabetes\" \nplt.title('Features responsible for diabetes') \n#Label x axis as \"Observations\" \nplt.xlabel('Observations') \n#Label y axis as \"Values\" \nplt.ylabel('Values') \n#Display the figure \nplt.show() \n\n \n#create a line plot of different color for each feature \ndf.plot(kind='line', color=['red','blue','brown','green'], \nmarker='*',markersize=10,linewidth=3,linestyle=\"--\") \n# Set title to \"Features responsible for diabetes\" \nplt.title('Features responsible for diabetes') \n# Label x axis as \"Oberservations\" \nplt.xlabel('Oberservations') \n# Label y axis as \"Values\" \nplt.ylabel('Values') \n#Display the figure \nplt.show() \n\n##Plotting BAR Chart\n#plots a bar chart  \ndf.plot(kind='bar', title='diabetes prediction') \n#set title, set xlabel and ylabel \nplt.xlabel('Obervations') \nplt.ylabel('Values') \nplt.show()\n\n#Customising bar Chart \ndf.plot(kind ='bar',title ='diabetes prediction', \ncolor=['red','yellow','purple','pink'],edgecolor='Green', linewidth=2, \nlinestyle='--') \n#set title, set xlabel and ylabel \nplt.xlabel('Obervations') \nplt.ylabel('Values') \nplt.show() \n\n##Plotting SCATTER plot\nx= df['Age'] \ny= df['Glucose'] \nplt.scatter(x,y) \nplt.title('Diabetes Prediction') \nplt.xlabel('Age') \nplt.ylabel('Glucose') \nplt.show()\n\n#Customising scatter Plot \nx= df['Glucose'] \ny= df['Insulin'] \nplt.scatter(x,y,color='red',linewidth=2,marker='*',edgecolor='red') \nplt.title('Diabetes Prediction') \nplt.xlabel('Glucose') \nplt.ylabel('Insulin') \nplt.show()\n\n#Plotting HISTOGRAM\ndf.plot(kind='hist',title='diabetes prediction') \nplt.show()\n\n#Customising histogram\ndf.plot(kind='hist',edgecolor='Blue',linewidth=2,linestyle=':',fill=False, hatch='o') \nplt.show()\n\n#Plotting PIE Chart \ndf.plot(kind='pie',y='Glucose', title='Diabetes Prediction', legend=False, autopct=\"%.2f%%\") \nplt.show() \n\n#Plotting Quartiles and Box plot \ndf.plot(kind='box') \n#set title,xlabel,ylabel \nplt.title('Diabetes Prediction') \nplt.xlabel('Index') \nplt.ylabel('Values') \nplt.show() \n\ndf.plot(kind='box',title='Diabetes Prediction',color='red',vert=False)"
  },
  {
    "title": "titanic-eda",
    "code": "import pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(r\"  .csv\")  \nprint(df.head()) \n \nprint(df.info()) \n\nprint(df.describe()) \n\n##1-Univariate Analysis \n#Distribution of Survival \nsns.countplot(x='Survived', data=df) \nplt.title('Survival Distribution') \nplt.xlabel('Survived') \nplt.ylabel('Count') \nplt.show()\n\n#Distribution of Passenger Classes \nsns.countplot(x='Pclass', data=df) \nplt.title('Passenger Class Distribution') \nplt.xlabel('Pclass') \nplt.ylabel('Count') \nplt.show()\n\n#Age Distribution \nsns.histplot(df['Age'].dropna(), bins=30, kde=True) \nplt.title('Age Distribution') \nplt.xlabel('Age') \nplt.ylabel('Frequency') \nplt.show()\n\n##2-Bivariate Analysis \n#Survival Rate by Gender \nsns.barplot(x='Sex', y='Survived', data=df)\nplt.title('Survival Rate by Gender') \nplt.xlabel('Sex') \nplt.ylabel('Survival Rate') \nplt.show()\n\n#Survival Rate by Passenger Class \nsns.barplot(x='Pclass', y='Survived', data=df) \nplt.title('Survival Rate by Passenger Class') \nplt.xlabel('Pclass') \nplt.ylabel('Survival Rate') \nplt.show()\n\n#Survival Rate by Embarked \nsns.barplot(x='Embarked', y='Survived', data=df) \nplt.title('Survival Rate by Embarked') \nplt.xlabel('Embarked') \nplt.ylabel('Survival Rate') \nplt.show() \n\n# Fare vs. Survival \nsns.boxplot(x='Survived', y='Fare', data=df) \nplt.title('Fare vs. Survival') \nplt.xlabel('Survived') \nplt.ylabel('Fare') \nplt.show() \n\n##3-Multivariate Analysis \n# Survival Rate by Age and Passenger Class \nsns.scatterplot(x='Age', y='Fare', hue='Survived', style='Pclass', data=df) \nplt.title('Survival Rate by Age and Passenger Class') \nplt.xlabel('Age') \nplt.ylabel('Fare') \nplt.show() \n\n# Pairplot for Selected Features \nsns.pairplot(df[['Age', 'Fare', 'Pclass', 'Survived']].dropna(), hue='Survived') \nplt.title('Pairplot of Selected Features') \nplt.show()"
  },
  {
    "title": "prob-survivalon",
    "code": "1. Data Collection \nimport pandas as pd \ndata = pd.read_csv(r\" .csv\",encoding=\"])\ndata\n\n2. Data Preparation \ndata = data[['Survived', 'Pclass', 'Sex', 'Age']]  \ndata\n\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata\n\ndata['Sex'] = data['Sex'].map({'male': 0, 'female': 1}) \ndata\n\n3. Split the Data \nfrom sklearn.model_selection import train_test_split \nX = data[['Pclass', 'Sex', 'Age']] \ny = data['Survived'] \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ndata\n\n4. Build a Model \nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmodel = LogisticRegression() \nmodel.fit(X_train, y_train) \ny_pred = model.predict(X_test) \naccuracy = accuracy_score(y_test, y_pred) \nconf_matrix = confusion_matrix(y_test, y_pred) \nprint(f'Accuracy: {accuracy}') \nprint(f'Confusion Matrix:\\n{conf_matrix}') \ndata\n\n5. Predict Probabilities        \nprobabilities = model.predict_proba(X_test)[:, 1]  # Probability of survival \nprint(f'Accuracy: {accuracy}') \nprint(f'Confusion Matrix:\\n{conf_matrix}')  \nprint(f'Predicted Probabilities of Survival: {probabilities}')\ndata"
  },
  {
    "title": "linear-regression",
    "code": "import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_squared_error, r2_score \ndata = pd.read_csv(r\"  .csv\")\ndata\n\n##1-Simple Linear Regression  \n#Split the data    \nsimple_data = data[['YearsExperience', 'Salary']]  \nX_simple = simple_data[['YearsExperience']] \ny_simple = simple_data['Salary'] \nX_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(X_simple, y_simple, test_size=0.2, random_state=42) \nsimple_model = LinearRegression() \nsimple_model.fit(X_train_simple, y_train_simple)\n\n# Make predictions \ny_pred_simple = simple_model.predict(X_test_simple) \n\n# Evaluate the Simple Linear Regression model \nmse_simple = mean_squared_error(y_test_simple, y_pred_simple) \nr2_simple = r2_score(y_test_simple, y_pred_simple) \nprint(f'Simple Linear Regression MSE: {mse_simple:.2f}') \nprint(f'Simple Linear Regression R²: {r2_simple:.2f}') \n\n# Visualize Simple Linear Regression \nplt.scatter(X_test_simple, y_test_simple, color='blue', label='Actual') \nplt.plot(X_test_simple, y_pred_simple, color='red', label='Predicted') \nplt.title('Simple Linear Regression') \nplt.xlabel('Years of Experience') \nplt.ylabel('Salary') \nplt.legend() \nplt.show() \n\n##2-Multiple Linear Regression       \nmultiple_data = data[['YearsExperience', 'Age', 'EducationLevel', 'Salary']] \nX_multiple = multiple_data[['YearsExperience', 'Age', 'EducationLevel']]\ny_multiple = multiple_data['Salary'] \n\n# Split the data \nX_train_multiple, X_test_multiple, y_train_multiple, y_test_multiple = train_test_split(X_multiple, y_multiple, test_size=0.2, random_state=42) \nmultiple_model = LinearRegression() \nmultiple_model.fit(X_train_multiple, y_train_multiple) \n\n# Make predictions \ny_pred_multiple = multiple_model.predict(X_test_multiple) \ny_pred_multiple\n\n# Evaluate the Multiple Linear Regression model  \nmse_multiple = mean_squared_error(y_test_multiple, y_pred_multiple) \nr2_multiple = r2_score(y_test_multiple, y_pred_multiple) \nprint(f'Multiple Linear Regression MSE: {mse_multiple:.2f}') \nprint(f'Multiple Linear Regression R²: {r2_multiple:.2f}')\n\n# Visualize Multiple Linear Regression \nplt.scatter(y_test_multiple, y_pred_multiple, color='blue', label='Predicted') \nplt.plot([y_test_multiple.min(), y_test_multiple.max()],\n         [y_test_multiple.min(), y_test_multiple.max()],\n         color='red', label='Ideal Fit')\nplt.title('Multiple Linear Regression: Predicted vs Actual') \nplt.xlabel('Actual Salary') \nplt.ylabel('Predicted Salary') \nplt.legend() \nplt.show()"
  },
  {
    "title": "decision-tree-iris",
    "code": "import pandas as pd \nimport numpy as np \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report \nimport matplotlib.pyplot as plt \nfrom sklearn import tree \n\n# Load the Iris dataset  \nfrom sklearn.datasets import load_iris \niris = load_iris()\ndata = pd.DataFrame(data=iris.data, columns=iris.feature_names) \ndata['target'] = iris.target \nprint(data.head()) \n\n# Split the data \nX = data.drop('target', axis=1) \ny = data['target']       \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n\n# Create and train the Decision Tree Classifier \ndt_classifier = DecisionTreeClassifier(random_state=42) \ndt_classifier.fit(X_train, y_train) \n\n# Make predictions \ny_pred = dt_classifier.predict(X_test)\n\n# Evaluate the model \naccuracy = accuracy_score(y_test, y_pred) \nconf_matrix = confusion_matrix(y_test, y_pred) \nclass_report = classification_report(y_test, y_pred) \nprint(f'Accuracy: {accuracy:.2f}') \nprint(f'Confusion Matrix:\\n{conf_matrix}') \nprint(f'Classification Report:\\n{class_report}') \n\n# Visualize the Decision Tree \nplt.figure(figsize=(12,8)) \ntree.plot_tree(dt_classifier, feature_names=iris.feature_names, \nclass_names=iris.target_names, filled=True) \nplt.title('Decision Tree Classifier') \nplt.show()"
  },
  {
    "title": "and",
    "code": "import numpy as np \nimport matplotlib.pyplot as plt \nfrom keras.models import Sequential \nfrom keras.layers import Dense \n\n# Prepare the dataset for AND gate \nX_and = np.array([[0, 0], \n[0, 1], \n[1, 0], \n[1, 1]]) \ny_and = np.array([[0], [0], [0], [1]])  # AND gate outputs \n\n# Prepare the dataset for NAND gate \nX_nand = np.array([[0, 0], \n[0, 1], \n[1, 0],\n[1, 1]]) \ny_nand = np.array([[1], [1], [1], [0]])  # NAND gate outputs \n\n# Function to create and train the model \ndef create_and_train_model(X, y): \n # Create the model \n model = Sequential() \n model.add(Dense(2, input_dim=2, activation='sigmoid'))  # Hidden layer \n model.add(Dense(1, activation='sigmoid'))  # Output layer \n # Compile the model     \n model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n # Train the model \n model.fit(X, y, epochs=5000, verbose=0) \n return model \n\n# Train the AND gate model \nand_model = create_and_train_model(X_and, y_and) \nprint(\"AND Gate Predictions:\") \nprint(and_model.predict(X_and))\n \n# Train the NAND gate model \nnand_model = create_and_train_model(X_nand, y_nand) \nprint(\"\\nNAND Gate Predictions:\")\nprint(nand_model.predict(X_nand)) \n\n# Visualize predictions \ndef plot_predictions(model, X, title): \n predictions = model.predict(X) \n plt.figure() \n plt.scatter(X[:, 0], X[:, 1], c=predictions.flatten(), cmap='coolwarm', s=100) \n plt.title(title) \n plt.xlabel('Input 1') \n plt.ylabel('Input 2') \n plt.colorbar(label='Output') \n plt.xlim(-0.5, 1.5) \n plt.ylim(-0.5, 1.5) \n plt.axhline(0.5, color='grey', lw=0.5, ls='--') \n plt.axvline(0.5, color='grey', lw=0.5, ls='--') \n plt.show() \n\n# Plotting the predictions for both gates \nplot_predictions(and_model, X_and, \"AND Gate Predictions\") \nplot_predictions(nand_model, X_nand, \"NAND Gate Predictions\")"
  },
  {
    "title": "or-nor",
    "code": "import numpy as np \nimport matplotlib.pyplot as plt \nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense \n\n# Prepare the dataset for OR gate \nX_or = np.array([[0, 0], \n[0, 1], \n[1, 0], \n[1, 1]]) \ny_or = np.array([[0], [1], [1], [1]])  # OR gate outputs \n\n# Prepare the dataset for NOR gate\nX_nor = np.array([[0, 0], \n[0, 1], \n[1, 0], \n[1, 1]]) \ny_nor = np.array([[1], [0], [0], [0]])  # NOR gate outputs\n\n# Function to create and train the model \ndef create_and_train_model(X, y): \n # Create the model \n model = Sequential() \n model.add(Dense(2, input_dim=2, activation='sigmoid'))  # Hidden layer \n model.add(Dense(1, activation='sigmoid'))  # Output layer \n # Compile the model       \n model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n # Train the model \n model.fit(X, y, epochs=5000, verbose=0) \n return model \n\n# Train the OR gate model \nor_model = create_and_train_model(X_or, y_or) \nprint(\"OR Gate Predictions:\") \nprint(or_model.predict(X_or)) \n\n# Train the NOR gate model \nnor_model = create_and_train_model(X_nor, y_nor) \nprint(\"\\nNOR Gate Predictions:\") \nprint(nor_model.predict(X_nor)) \n\n# Visualize predictions \ndef plot_predictions(model, X, title): \n predictions = model.predict(X) \n plt.figure() \n plt.scatter(X[:, 0], X[:, 1], c=predictions.flatten(), cmap='coolwarm', s=100) \n plt.title(title) \n plt.xlabel('Input 1') \n plt.ylabel('Input 2') \n plt.colorbar(label='Output') \n plt.xlim(-0.5, 1.5) \n plt.ylim(-0.5, 1.5) \n plt.axhline(0.5, color='grey', lw=0.5, ls='--') \n plt.axvline(0.5, color='grey', lw=0.5, ls='--') \n plt.show()\n\n# Plotting the predictions for both gates \nplot_predictions(or_model, X_or, \"OR Gate Predictions\") \nplot_predictions(nor_model, X_nor, \"NOR Gate Predictions\")"
  }

];
